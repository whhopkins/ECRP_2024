Experiments at the Large Hadron Collider (LHC) have confirmed many predictions of the highly successful Standard Model (SM), including the landmark discovery of the Higgs boson. Despite its success, the SM does not account for several observed phenomena, such as dark matter and the matter-antimatter asymmetry, thereby fueling the search for physics Beyond the Standard Model (BSM). Future LHC upgrades will shift focus from increasing energy to enhancing precision. Crucially, enhancing the efficiency of measurements and minimizing systematic uncertainties are vital for future breakthroughs in collider physics. Increased efficiency effectively increases the usable data, akin to extending LHC operation times, while reducing systematic uncertainties further heightens the sensitivity to subtle deviations from SM predictions. This shift towards precision comes as machine learning (ML) has become an indispensable tool in High-Energy Physics (HEP), improving particle identification and the separation of signal from background processes. Nevertheless, ML's effectiveness is hampered by its sensitivity to data-simulation discrepancies and other experimental systematic uncertainties. The creation of a framework aimed at incorporating advanced domain-adaptation techniques, which are methods that allow ML models to be trained in one domain (e.g., using simulation) and be applied to another domain (e.g., recorded data), addresses these challenges. This proposal will develop a framework that leverages methods such as adversarial learning and distance correlation to enhance the robustness of ML models, making them more resilient against varied experimental conditions and simulation inaccuracies. The implementation of this framework is expected to reduce uncertainties, thereby boosting the discovery potential at the HL-LHC, especially in precision measurements crucial for probing BSM physics. This framework is not limited to ATLAS but is poised to benefit a broad spectrum of experiments across the HEP frontiers.
